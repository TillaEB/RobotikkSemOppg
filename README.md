# Semesteroppgave for ELE306 Robotikk 游뱄 
## Tirsdag 25.10 
Today is arm day 
Vi jobber med arm til roboten. Kravet er at den skal n친 potter som st친r p친 gulvet helt ned til 20cm og potter opp til 150cm. Basen v친r er 40cm h칮y, inklusivt 10 cm radius p친 hjulene vil dette gi at basen p친 armen er festet 50 cm over gulvet. 
Ut i fra hvordan vi har tenkt at roboten skal kj칮re opp til planetene vil det variere om planten havner p친 h칮yre eller venstre siden p친 basen. Alts친 m친 vi har et ledd med rotasjon rundt z aksen (koordinatsystem 0 vil v칝re likt som body corrdinate til roboten) 

Armen skal kun bevege seg fra venstre til h칮yre og motsatt via fronten p친 roboten. Dette fordi at det ikke skal bli konflikt mellom vanntanken og armen. Armen kan kun bevege seg mellom 0 og pi grader 
![image](https://user-images.githubusercontent.com/112081507/197809867-5bff5241-7db5-4e70-a6a1-6b58dde80460.png)

Brukt veldig vitenskapelige metoder for finne ut om robotarmen 
![image](https://user-images.githubusercontent.com/112081507/197810755-1f66b638-53d1-41b8-ab6a-40ea59bb4cf7.png)

Sp칮rsm친l til hjelpetime 

- Robotarmen, skal man designe selv eller finne en som allerede finnes 
- Hvordan er det 친 tegne en robotarm i ros, vanskelig? 
- I f칮lge lattice skal roboten egentlig klare 친 kj칮re ruten, men n친r vi simulerer kommer den noen ganger ikke frem til m친let. Vi har noen ruter 친 vise til hvor den klarer det fint. Hvis det er viktig at den klarer 친 kj칮re mellom alle plantene trenger vi hjelp. 


## Mandag 17.10
Begynte 친 skrive inn det vi hadde fra Oblig 1 p친 rapporten, og s친 p친 hvilke sensorer vi trenger. 

-Kamera sensor for 친 identifisere eventuelle hindringer i veibanen, og finne frem til riktig sted den skal vanne.
-Fuktighetssensor til 친 m친le fuktigheten i jorden til planten.
-Vektsensor for 친 kunne detektere om vanntanken er tom/full.

Gikk for Intel RealSense D415. Dette kamerasystemet egner seg godt til v친r bruk, og har innebygget RGB fargesensor. Selv om vi ikke skal bruke RGB i denne oppgaven, vil det gi mulighet til 친 videreutvikle roboten, om 칮nsket, til 친 kunne plukke vekk vissne blader uten 친 m친tte skifte kamera. 



## Torsdag 13.10 

Waterino--> H2rObot

F친tt kartet inn i fusion som 3D model: 

<img width="549" alt="image" src="https://user-images.githubusercontent.com/112080695/195574469-ef51f6e5-53c1-46ca-8b14-ed7fdeec14b8.png">

Se stl fil. 
For 친 f친 inn i fusion: mesh - insert mesh (med bl친 pil over create) - velg stl fil (ferdig skalert)


## Onsdag 12.10 
Arbeider i dag med 친 f친 kj칮pesenteret inn i fusion 360. Dette har vi n친 klart, n친 handler det om skalering. 
Ser ogs친 p친 친 f친 stl fil fra fusion360 inn i ROS s친 vi kan lage en ny verden. 
Link vi kanskje kan bruke: https://classic.gazebosim.org/tutorials?tut=build_model&cat=build_robot  

Ble tipset om IMU i forelesning i dag. Brukes til dead reckogning, som vi skal ha

## Tirsdag 11.10
Vi har blitt enige om at punktene vi plotter i MatLab er omr친det rundt planten, og ikke n칮dvendigvis akuratt der planten st친r. Roboten kj칮rer derfor til omr친det rundt planten, mens robotarmen vil ta ansvar for strekningen til den faktiske planten. Siden vi har byttet til car-like robot vil vi at roboten skal komme "p친 siden" av planten, og ikke peke nesen mot planten. Dette er mest praktisk i forhold til at den skal kj칮re videre etter vanning.
Fortvil ikke, det g친r fint 친 svinge 游땚 :
![image](https://user-images.githubusercontent.com/112081691/195098064-5a73eb01-1522-45e3-84ce-fd3770682631.png)

Vi har n친 funnet ut og forst친tt mer av hvordan vi skal navigere roboten i lattice planner i Matlab - og knukket koden for hvordan 풪 fungerer. N친 gir alt mening.

<img width="508" alt="image" src="https://user-images.githubusercontent.com/112080695/198144718-d327b7b3-8691-4741-ad1d-e036dd500247.png">

## Torsdag 06.10
Samme uke, ny diskusjon rundt navigasjonsmetode.
Etter mye om og men har vi kommet fram til at det er mer fornuftig 친 velge car-like robot. Vi fortsetter med samme lokaliseringsmetode, men endrer controller til "follow a trajectory".
Vi har funnet ut at det ikke er n칮dvendig 친 bruke omnidirectional robot ettersom at vi har et stort kj칮pesenter som roboten skal navigere i. Vi f칮ler ogs친 at omnidirectioal robot blir for komplekst og fjernt, og bytter derfor til en robot som vi kan ha mer eierskap over, som vi fors친r oss mer p친. 
Arbeidet vi har gjort frem til n친 vil likevel ikke v칝re bortkastet. Vi har brukt mye tid p친 latticeplanner tidligere, og har n친 behov for en navigasjonsmetode som krever at man tar hensyn til robotens kinematikk, derfor vil vi fortsette arbeidet med lattice planner. 

Jobbet med lattice for 친 skj칮nne hvordan de forskjellige funksjonene funker, root, grid, inflate gir endelig mening. 
Forsket frem og tilbake for 친 finne ut hvilke parametre som ga oss et best mulig resultat. 
For 친 unng친 at lattice grid g친r helt inntil hindringer brukte vi inflate=1. Dette gir en "d칮dsone" p친 1 meter fra hindringene. Noen steder hvor det er stolper i kartet g친r strekene tvers over hindringer. Dette har vi ikke klart 친 unng친. Noen steder vil den ogs친 kollidere med hj칮rne av en butikk osv.  

M친ten vi har tatt hensyn til dette: 
 - Vi har s칮rget for 친 legge inn mellompunkt noen steder hvor det kreves slik at roboten ikke kj칮rer en hindring. 
 - Det koster mer 친 svinge enn 친 kj칮re rett, pr칮ver 친 holde den mest mulig "midt" i kartet og p친 en linje. 
 - Tilpasset hvilken vinkel den skal ende opp i. 
 
![image](https://user-images.githubusercontent.com/112081507/195333800-16748f94-4809-4dac-a0dd-3eadff4591dc.png)


Vi velger Grid=3 for dette gir et fornuftig antall noder. Griddet ligger da opp til at roboten snur 180 grader via en halvsirkel med radius 1.5meter. V친r robot har en avstand p친 0.60m (cc) mellom hjulene (wheelbase) og en maksimal sving p친 forhulene p친 40 grader. 
Turning radius for v친r robot blir da 
Tr=wb/tan(maksSving)=0.60m/tan(40 deg)=0.7149m. 
Dette betyr at roboten v친r ikke vil ha problemer med 친 utf칮re en 180 graders sving slik som grid er satt opp.

Rootnode satt vi i midten for at den skulle bre seg utover. 칀 sitte den i et f.eks et hj칮rne ga mye f칝rre noder, og veldig rart plasserte noder. 
Vi har tenkt oss 8 "soner" hvor det vil befinne seg planter, og har testet at roboten kj칮rer en kollisjonsfri rute mellom plantene. 
Roboten vil kj칮re en fast rute, og ha en fast rekkef칮lge den bes칮ker plantene i. 

## Onsdag 05.10 
Tilla har fikset skalering p친 bildet slik at kj칮pesenteret ikke er 1.6 km bredt lengre.
Har g친tt gjennom punktene til oppgaven for 친 skaffe oss en bedre oversikt over hva som skal v칝re med og fremdrift i oppgaven. Ligger tilsynelatende greit ann i forhold til fremdrift i faget. Fokus fremover vil v칝re matlab og simuleringer. Vi m친 lese oss opp p친 sensorer og kontrollstrategi, og f친 bestemt oss for det i l칮pet av kort tid. 


## Tirsdag 04.10 
Ny uke, ny diskusjon rundt navigasjonsmetode. 
Vi har lenge v칝rt l친st p친 lattice planner, men ettersom at roboten v친r ikke har naturlig svingradius er dette noe vi m친 legge inn selv. RRT blir overkill for en holonomrobot. Vi 칮nsker 친 bruke roadmap methods, da st친r vi igjen med en siste metode, nemlig PRM, som er der vi lander for denne gang. (Dette avviker fra det vi har levert inn p친 obligen) 
Senere i uken er det PDR vi m친 derfor gj칮re litt om p친 det vi har gjort til n친. 

Vi innser at vi har letet etter gode grunner til 친 bruke lattice og ikke klart 친 v칝re helt objektiv i diskusjonen. 
Neste steg n친 er 친 se hvor mange noder vi trenger for 친 dekke en tilfredsstillende del av kartet. 

### MATLAB 
- Hvordan g친 fra bilde til occupancy grid: 
https://se.mathworks.com/help/nav/ref/binaryoccupancymap.html

Se fil: bildekart.m for v친rt kart. 
Orginalt kart: se fil sistekart.

Occupancy grid:

<img width="622" alt="image" src="https://user-images.githubusercontent.com/112080695/194028460-3c6d7fb2-220f-4006-a078-172df5f3e214.png">

- PRM i matlab: 
https://se.mathworks.com/help/robotics/ug/path-planning-in-environments-of-difference-complexity.html

Se ogs친 https://se.mathworks.com/help/robotics/ref/mobilerobotprm.html


Se fil PRMpathfinder.m for v친r simulering

PRM planlegging:

<img width="636" alt="image" src="https://user-images.githubusercontent.com/112080695/194025442-64d630f1-55f3-49b4-a40b-9568f11d74af.png">

Kart med punkter for planter:

![image](https://user-images.githubusercontent.com/112080695/194028014-69e30c51-5896-4134-a2e4-04ad769adc12.png)

- Planleggings metoder i matlab: 
https://se.mathworks.com/help/nav/motion-planning.html

Se under motion planning. 

## Fredag 30.09 
I dag har vi jobbet med PDR, og er snart ferdig med den. 
Under diskusjonen tok vi oppigjen tr친den ang친ende navigasjonsmetode
![image](https://user-images.githubusercontent.com/112081691/193263608-ea6541b9-7457-4e71-a353-1063b812962c.png)
Argumenter hvor de tre metodene er like gode har vi ikke tatt med.
Vi konkluderer fermdeles med at Lattice er et godt valg for v친rt form친l 

## Torsdag 29.09
ENDELIG 
Mangler litt men snart ferdig kart 
![image](https://user-images.githubusercontent.com/112081507/192988671-f8e8f267-55dc-44c2-944f-ce75fed773c7.png)

## Tirsdag 27.09 
Funnet ut hvordan vi kan endre utseende p친 huset slik at vi kan tilpasse det til et kj칮pesenter. N친 m친 vi finne ut st칮rrelsesforholdene 
![image](https://user-images.githubusercontent.com/112081507/192486573-a000cb86-703a-441c-aeb4-38696940a00d.png)

Tilla har laget bilde av kj칮pesenteret p친 ipad og konvertert bildet til et occupancygrid som fungerer i matlab! Godt jobbbet! 
![image](https://user-images.githubusercontent.com/112081691/192516434-99699bd3-932c-4c35-99fb-92e269a5ec99.png)

Link til hvordan lattice koden er bygget opp 
https://github.com/petercorke/robotics-toolbox-matlab/blob/master/Lattice.m 


## S칮ndag 25.09
Blitt ferdig med oblig og gjort klart hvilke navigasjon- og kontrollmetode vi skal bruke. Samtidig snakket sm친tt om flere ting vi er litt usikre p친 som vi som planlagt skal ta opp med foreleser tirsdag.

## Fredag 23.09
Jobbet videre med oblig og f친tt til oppgave 2 og oppgave 4. 
Har f친tt svar fra foreleser ang m칮te om en del sp칮rsm친l. Dette m칮tet blir tirsdag etter kl 12.00.
Vi har bestemt oss for navigasjonsmetoden lattice planner. 

## Torsdag 22.09
Sendte i g친r melding til foreleser da vi var usikker p친 hvordan vi skulle n친 flere m친lpunkt. Om vi skulle behandle det som mange sm친 strekkninger med m친l og startpunkt eller et m친lpunkt med flere startpunkt. Etter veldig godt svar og tips fra foreleser skj칮nte vi mer hvordan vi m친tte tenke. 
Vi m친 g친 for roadmap method og 칮nsker 친 ta hensyn til kinematikken da vi velger en s친pass avansert robot. Da gjennst친r det bare to navigasjonsmetoder som vi m친 lese p친 og bestemme oss for, lattice og RRT 

Plan for dagen:
 - Tegne skjematisk tegning av basen til roboten (oppg 2)
 - Utvikle likninger for omni (oppg 3)
 - Holonom/ikke holonom begrunnelse (oppg 4) 
 
 Link til Robotino deler hardware:
 https://www.festo-didactic.com/int-en/services/robotino/hardware/?fbid=aW50LmVuLjU1Ny4xNy4zNC4xNDI5
 
 Link til youtube video 
 https://www.youtube.com/c/TommyHvidsten/videos
 https://www.youtube.com/watch?v=wwQQnSWqB7A
 
## Onsdag 21.09 
Forenklet kart av senteret med hindringer og d칮rer. 
<img width="689" alt="image" src="https://user-images.githubusercontent.com/112080695/191510127-eede91f6-79f2-4d07-9921-542b72f281b3.png">

Vi diskuterer 친 bruke omnidirectional(omni) robot, og da bruke og da bruke "readily available Robotino models for ROS simulations". 
<img width="521" alt="image" src="https://user-images.githubusercontent.com/112080695/191513361-a308e9b5-b575-4735-aa56-7290b7a337e9.png">
![image](https://user-images.githubusercontent.com/112080695/191513508-56013520-5b01-4cbd-8802-cd4f8ab7b709.png)
https://robots.ros.org/robotino/


S칮ppel g친r som uplanlagt hindring

### Omnidirectional robot 
https://www.researchgate.net/publication/221786657_Omnidirectional_Mobile_Robot_-_Design_and_Implementation 

## Tirsdag 20.09 
Diskusjon ang친ende hvilken type robot vi b칮r velge. 
Artikkelen under peker p친 problematikk ved "differential steering mobile robot(diff)"
http://www.robotplatform.com/knowledge/Classification_of_Robots/wheel_control_theory.html

Vi bestemte oss for 친 bruke 1.etg i Bergen Storsenter som mal til kartet. Gikk p친 senteret for 친 kartlegge hindringer. 


## S칮ndag 18.09 
Unders칮kt en del for 친 finne ut hvilken type robot vi burde velge, "car-like" eller "differential steering mobile robot(diff)". Med en differentialt styrt robot vil vi kunne ha muligheten til 친 snu roboten uten at den beveger seg fremover, noe som kan v칝re hensiktsmessig dersom den skulle manuvrere gjennom f.eks et omr친de med stoler osv. Pros ved 친 bruke differential steering og unicycle model er som sagt muligheten til 친 kunne snu seg, samt at den skal v칝re veldig vanlig 친 benytte og enkelt 친 estimere og kontrollere posisjonen. Et annet nettsted peker p친 at det kan v칝re vanskelig 친 styre rett frem og at den kanskje ikke kj칮rer og snur helt som forventet. V친r robot er tenkt 친 kj칮re etter kj칮pesenteret er stengt og s친 vurderer i f칮rste omgang at dette ikke vil v칝re et stort problem s친 lenge den n친r m친let. Et annet nettsted peker ogs친 p친 at nybegynnere burde brukke diff som hentyder at det er en enkel/enklere type robot. 


## Torsdag 15.09
Veiledningsm칮te med forelesere
Vi lurer p친 f칮lgende ting: Vil det v칝re flere veiledningssituasjoner og hvor ofte vil disse v칝re. I forhold til MATLAB, skal man skrive egen kode eller bearbeide/bruke skript lagt ut p친 Canvas? 

Fra m칮tet med veilederer: 
Navigasjonsstrategier kan vises hver for seg i matlab. Vi kan modifisere skriptene som er lagt ut, og kan endre p친 huset i toolboxen slik at det fremstiller et kj칮pesenter. 
Per n친 er planen 친 ha en robot per etasje dersom kj칮pesenteret g친r over flere plan. Arbeidet med oblig1 vil gjennspeile mye av det som skal v칝re med i PDR

Fra forelesning: 
PDR trenger ikke v칝re endelig l칮sning. Skal hansle om tema, hvordan vi tolker oppgaven, idder vi har hatt, samt ta opp noen ting fra kravdokumentet. 


## Tirsdag 06.09 
I dag valgte vi oppgave. Vi har valgt 친 lage en robot som skal vanne planter enten i hjemmet eller p친 f.eks et kj칮pesenter.
Vi har tenkt mest p친 en robot som er tenkt for et kj칮pesenter. 


## Torsdag 25.08
I dag har vi opprettet GitHub for semesteroppgaven. Vi tenker 친 skrive oppgaven online versjonen av Word. 
Vi har v칝rt innom tanken p친 oppgave om robot som vanner planter p친 kj칮pesenter og gaffeltruck. Ikke bestemt enda.

